### co-normalization

library(mixOmics)
library(limma)
library(sva)

# load Gains cohort data - g

g[1:5,1:5]
#         Probe CAP0019_1 CAP0020_5 CAP0021_1 CAP0022_5
#1 ILMN_1762337  4.770594  4.896686  4.143051  4.735957
#2 ILMN_2055271  5.504603  4.721227  5.068872  4.597434
#3 ILMN_1736007  3.666458  4.072066  4.664058  3.836351
#4 ILMN_2383229  4.186574  4.499400  4.898313  3.171909
#5 ILMN_1806310  4.073422  3.991380  3.812324  4.143627

rownames(g) <- g$Probe
g.m <- data.matrix(g[,-1])

g.m[1:5,1:5]

#             CAP0019_1 CAP0020_5 CAP0021_1 CAP0022_5 CAP0023_1
#ILMN_1762337  4.770594  4.896686  4.143051  4.735957  3.839883
#ILMN_2055271  5.504603  4.721227  5.068872  4.597434  5.317243
#ILMN_1736007  3.666458  4.072066  4.664058  3.836351  3.177338
#ILMN_2383229  4.186574  4.499400  4.898313  3.171909  4.375654
#ILMN_1806310  4.073422  3.991380  3.812324  4.143627  3.283559


##### PC analysis and dot plot - mixOmics

res = pca(t(g.m), ncomp = 10) # decomposing data to 10 components

## load mars endotypes data - exp.e

exp.e[1:5,1:5]
#              03_04_2013_A01_3213.CEL 03_04_2013_A03_3199.CEL 03_04_2013_A05_3193.CEL 03_04_2013_A06_3191.CEL 03_04_2013_A07_3170.CEL
#11715100_at                  2.430932                2.635036                2.346632                2.311040                2.334458
#11715101_s_at                2.590743                2.665903                2.748758                3.095418                3.057909
#11715102_x_at                2.639158                2.595763                2.552993                2.266556                2.413724
#11715103_x_at                2.151153                2.360794                2.845359                2.096779                2.575808
#11715104_s_at                2.184524                2.371379                2.078914                1.903558                2.150093

#### PC analysis MARS

res.1 = pca(t(exp.e), ncomp = 10) # decomposing data to 10 components

#plot directly from component frame
#png("xxxxx.png",height=2000,width=2000,res=300)
plot(res.1$x[,1],res.1$x[,2],pch=16,cex=1.5)
#abline(h=0,lty=2)
#abline(v=0,lty=2)
#dev.off()

#### read annotations - bowtie

anno <- read.table(file="Annotations_Bowtie.txt",header=T)

dim(anno)
[1] 85870     3


#### annotate expression data in GAINS by merge

head(anno)

anno$Probe <- anno$probeID

g.a <- merge(g,anno,by="Probe",all.x=T)

g.f<-g.a[!is.na(g.a["gennames"]),]

#    FP0118_3 CAP0381_1      probeID gennames                       biotype_gene
#7  11.155849  9.606998 ILMN_1651228    RPS28                     protein_coding
#8   6.418549  6.186745 ILMN_1651229    IPO13                     protein_coding
#9   4.297437  3.868199 ILMN_1651230   PRSS41 transcribed_unprocessed_pseudogene
#13  3.002593  5.965760 ILMN_1651237     CDT1                     protein_coding
#16  4.187401  3.879909 ILMN_1651253    WIPF3                     protein_coding

## collapse probes - only for microarray data
exp.g <- collapseRows(g.m,rows.gains$gennames,rownames(g.m),method="Average")

## vanish
vn.anno.2 <- collapseRows(vn.anno.1,rows.merge$gennames,rownames(vn.anno.1),method="Average")

#### extract the expression matix with collpased probes annotated by gene name

e.gains[1:5,1:5]
#        CAP0019_1 CAP0020_5 CAP0021_1 CAP0022_5 CAP0023_1
#A1BG     4.585531  4.396647  4.866465  4.216892  4.247291
#A1CF     3.583615  3.409115  3.445268  3.377611  3.250441
#A2M-AS1  5.181641  4.814242  4.819285  5.039779  3.999259
#A3GALT2  4.285990  4.219146  3.954903  3.873169  3.525412
#A4GALT   2.716849  2.543521  2.621022  2.407941  2.934856


e.mars <- exp.a$datETcollapsed
e.mars[1:5,1:5]
#        03_04_2013_A01_3213.CEL 03_04_2013_A03_3199.CEL 03_04_2013_A05_3193.CEL 03_04_2013_A06_3191.CEL 03_04_2013_A07_3170.CEL
#A1CF                   1.992758                2.022070                2.214409                1.962555                2.551708
#A2M                    1.990577                2.103996                2.467999                1.789704                2.205563
#A3GALT2                2.310610                2.216817                2.413800                2.193303                2.408598
#A4GALT                 2.314791                2.514968                2.450279                2.499034                2.586491
#A4GNT                  2.187031                2.120774                2.092695                2.483768                2.094641

#### mergeing the mars and gains exp data

e.gains <- exp.g$datETcollapsed
e.gains.df <- as.data.frame(e.gains)
e.mars.df <- as.data.frame(e.mars)
e.gains.df$gene <- rownames(e.gains.df)
e.mars.df$gene <- rownames(e.mars.df)
exp.x.df <- merge(e.mars.df,e.gains.df,by="gene")

##### first look at the PCs

res.1 = pca(t(exp.x), ncomp = 10) # decomposing data to 10 components

png("mars_gains_combo_PREcombat_PCplot.png",height=2000,width=2000,res=300)
plot(res.1$x[,1],res.1$x[,2],col=c("blue","orange")[p$batch],pch=16,cex=1)
dev.off()

#### of course the PC plot shows a massive separation between studies - normal stuff - prepare COMBAT

##### combat

library(sva)

p <- read.table(file="colnames_combined_cohorts_wBatch.txt",header=T)
batch=p$batch
#modcombat=model.matrix(~0,data=pheno$group.1)
exp.x.combat=ComBat(dat=exp.x,batch=batch,par.prior=TRUE,prior.plots=FALSE)

res.2 = pca(t(exp.x.combat), ncomp = 10) # decomposing data to 10 components

#plot directly from component frame
png("mars_gains_combo_combat_PCplot.png",height=2000,width=2000,res=300)
plot(res.2$x[,1],res.2$x[,2],col=c("blue","orange")[p$batch],pch=16,cex=1)
dev.off()

### MARS, GAinS and Stanford subtype annotations using respective published methods

###
### Jaccard similarity
###
library(jaccard)
set.seed(2024)

dat <- read.table(file.choose(),header=T)

head(dat)
##

table(dat$SRS)

dat$M1 <- ifelse(dat$MARS=="Mars1", 1,0)
dat$M2 <- ifelse(dat$MARS=="Mars2", 1,0)
dat$M3 <- ifelse(dat$MARS=="Mars3", 1,0)
dat$M4 <- ifelse(dat$MARS=="Mars4", 1,0)
dat$S1 <- ifelse(dat$SRS=="SRS1", 1,0)
dat$S2 <- ifelse(dat$SRS=="SRS2", 1,0)
dat$S3 <- ifelse(dat$SRS=="SRS3", 1,0)
dat$SW1 <- ifelse(dat$Stanford=="S1", 1,0)
dat$SW2 <- ifelse(dat$Stanford=="S2", 1,0)
dat$SW3 <- ifelse(dat$Stanford=="S3", 1,0)

dat.1 <- dat[,-(2:4)]
rownames(dat.1)<-dat.1$ID

dat.m <-data.matrix(dat.1[,-1])

jac.1 <- jaccard(dat.1$M1,dat.1$S1)
jac.2 <- jaccard(dat.1$M2,dat.1$S1)
jac.3 <- jaccard(dat.1$M3,dat.1$S1)
jac.4 <- jaccard(dat.1$M4,dat.1$S1)
jac.5 <- jaccard(dat.1$M1,dat.1$S2)
jac.6 <- jaccard(dat.1$M2,dat.1$S2)
jac.7 <- jaccard(dat.1$M3,dat.1$S2)
jac.8 <- jaccard(dat.1$M4,dat.1$S2)
jac.9 <- jaccard(dat.1$M1,dat.1$S3)
jac.10 <- jaccard(dat.1$M2,dat.1$S3)
jac.11 <- jaccard(dat.1$M3,dat.1$S3)
jac.12 <- jaccard(dat.1$M4,dat.1$S3)
jac.13 <- jaccard(dat.1$M1,dat.1$SW1)
jac.14 <- jaccard(dat.1$M2,dat.1$SW1)
jac.15 <- jaccard(dat.1$M3,dat.1$SW1)
jac.16 <- jaccard(dat.1$M4,dat.1$SW1)
jac.17 <- jaccard(dat.1$S1,dat.1$SW1)
jac.18 <- jaccard(dat.1$S2,dat.1$SW1)
jac.19 <- jaccard(dat.1$S3,dat.1$SW1)
jac.20 <- jaccard(dat.1$M1,dat.1$SW2)
jac.21 <- jaccard(dat.1$M2,dat.1$SW2)
jac.22 <- jaccard(dat.1$M3,dat.1$SW2)
jac.23 <- jaccard(dat.1$M4,dat.1$SW2)
jac.24 <- jaccard(dat.1$S1,dat.1$SW2)
jac.25 <- jaccard(dat.1$S2,dat.1$SW2)
jac.26 <- jaccard(dat.1$S3,dat.1$SW2)
jac.27 <- jaccard(dat.1$M1,dat.1$SW3)
jac.28 <- jaccard(dat.1$M2,dat.1$SW3)
jac.29 <- jaccard(dat.1$M3,dat.1$SW3)
jac.30 <- jaccard(dat.1$M4,dat.1$SW3)
jac.31 <- jaccard(dat.1$S1,dat.1$SW3)
jac.32 <- jaccard(dat.1$S2,dat.1$SW3)
jac.33 <- jaccard(dat.1$S3,dat.1$SW3)




### Jaccard distances and probabilities 
### Mars1 to SRS1 = 0.1119005 
### Mars1 to SRS2 = 0.2264398 
### Mars2 to SRS1 = 0.5667939
### Mars2 to SRS2 = 0.1376884
### Mars3 to SRS1 = 0.0192044
### Mars3 to SRS2 = 0.4598338
### Mars4 to SRS1 = 0.02934537
### Mars4 to SRS2 = 0.07876231
### Mars1 to SW1 = 0.1081594
### Mars2 to SW1 = 0.4753788
### Mars3 to SW1 = 0.0339233
### Mars4 to SW1 = 0.035
### Mars1 to SW2 =  0.1013289
### Mars2 to SW2 = 0.06319703
### Mars3 to SW2 = 0.5087041
### Mars4 to SW2 = 0.1103604
### Mars1 to SW3 = 0.2706935
### Mars2 to SW3 = 0.2091918
### Mars3 to SW3 = 0.1138211
### Mars4 to SW3 = 0.01530612
### S1 to SW1 = 0.4787879
### S2 to SW1 = 0.115508
### S1 to SW2 = 0.02918782
### S2 to SW2 = 0.5327869
### S1 to SW3 = 0.2156197
### S2 to SW3 = 0.241838
###
### Markov clustering
###


library(MCL)

dat.mcl <- read.table(file.choose(),header=T)
dat.mcl

#M1         M2        M3         M4         S1         S2       SW1        SW2        SW3
#M1  1.0000000 0.00000000 0.0000000 0.00000000 0.11190050 0.22643980 0.1081594 0.10132890 0.27069350
#M2  0.0000000 1.00000000 0.0000000 0.00000000 0.56679390 0.13768840 0.4753788 0.06319703 0.20919180
#M3  0.0000000 0.00000000 1.0000000 0.00000000 0.01920440 0.45983380 0.0339233 0.50870410 0.11382110
#M4  0.0000000 0.00000000 0.0000000 1.00000000 0.02934537 0.07876231 0.0350000 0.11036040 0.01530612
#S1  0.1119005 0.56679390 0.0192044 0.02934537 1.00000000 0.00000000 0.4787879 0.02918782 0.21561970
#S2  0.2264398 0.13768840 0.4598338 0.07876231 0.00000000 1.00000000 0.1155080 0.53278690 0.24183800
#SW1 0.1081594 0.47537880 0.0339233 0.03500000 0.47878790 0.11550800 1.0000000 0.00000000 0.00000000
#SW2 0.1013289 0.06319703 0.5087041 0.11036040 0.02918782 0.53278690 0.0000000 1.00000000 0.00000000
#SW3 0.2706935 0.20919180 0.1138211 0.01530612 0.21561970 0.24183800 0.0000000 0.00000000 1.00000000

mcl.1 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=1)
mcl.2 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=2)
mcl.3 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=3)
mcl.4 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=4)
mcl.5 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=5)
mcl.6 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=6)
mcl.7 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=7)
mcl.8 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=8)
mcl.9 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=9)
mcl.10 <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=10)

mcl <- mcl(x=dat.mcl, addLoops=T, allow1=F, inflation=2)
mcl


##
## Hyper test enrichment
##

phyper(overlap-1, S1, total-S1, M1, lower.tail= FALSE)
phyper(overlap-1, S2, total-S2, M1, lower.tail= FALSE)
phyper(overlap-1, S1, total-S1, M2, lower.tail= FALSE)
phyper(overlap-1, S2, total-S2, M2, lower.tail= FALSE)
phyper(overlap-1, SW1, total-SW1, M1, lower.tail= FALSE)
phyper(overlap-1, SW2, total-SW2, M1, lower.tail= FALSE)
....

### execute for all combinations

### select core

dat.1$CSE2.core <- ifelse((dat.1$M1==1&dat.1$S2==1&dat.1$SW3==1),"yes","no")
dat.1$CSE1.core <- ifelse((dat.1$M2==1&dat.1$S1==1&dat.1$SW1==1),"yes","no")
dat.1$CSE3.core <- ifelse((dat.1$M3==1&dat.1$S2==1&dat.1$SW2==1),"yes","no")

table(dat.1$CSE1.core)
table(dat.1$CSE2.core)
table(dat.1$CSE3.core)

dat.core <- subset(dat.1,dat.1$CSE1.core=="yes"|dat.1$CSE2.core=="yes"|dat.1$CSE3.core=="yes")
dim(dat.core)

write.table(dat.core,file="coreSamples_CSE.txt")

dim(exp.consensus)
# [1] 7260  1122


####
### classifier derivation

library(CMA)
library(randomForest)

set.seed(2024)

phenos.1 <- dat.core

tenCVdat <- GenerateLearningsets(n=460,y=as.factor(phenos.1$CSE), method = "CV", fold=10, niter=10, strat =TRUE)
sel <- GeneSelection(t(exp.norm), y=as.factor(phenos.1$CSE), learningsets = tenCVdat, method = "kruskal", scheme="one-vs-all")

class_rf_0 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=1)
class_rf_1 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=2)
class_rf_2 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=3)
class_rf_3 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=4)
class_rf_4 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=5)
class_rf_5 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=6)
class_rf_6 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=7)
class_rf_7 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=8)
class_rf_8 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=9)
class_rf_9 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=10)
class_rf_10 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=12)
class_rf_11 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=14)
class_rf_12 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=16)
class_rf_13 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=18)
class_rf_14 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=20)
class_rf_15 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=25)
class_rf_16 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=30)
class_rf_17 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=40)
class_rf_18 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=50)
class_rf_19 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=75)
class_rf_20 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=100)
class_rf_21 <- classification(t(exp.norm), as.factor(phenos.1$CSE), learningsets = tenCVdat, classifier = rfCMA, genesel=sel,nbgene=150)

dalike <- list(class_rf_0,class_rf_1,class_rf_2,class_rf_3,class_rf_4,class_rf_5,class_rf_6,class_rf_7,class_rf_8,class_rf_9,class_rf_10,class_rf_11,class_rf_12,class_rf_13,class_rf_14,class_rf_15,class_rf_16,class_rf_17,class_rf_18,
               class_rf_19,class_rf_20,class_rf_21)
png("classifier_error_metrics.png",height=1000,width=3000,res=300)
par(mfrow = c(1,3))
comparison <- compare(dalike,plot = TRUE,measure = c("misclassification", "brier score", "average probability"), col=c("white"))#,"white","white","white","white","white","white","white","white","white","white","white","white","white","white"))
abline(h=0.05,col="red")
dev.off() 

print(comparison)



# misclassification brier.score average.probability
#rf          0.06586957  0.09475486           0.9019465
#rf2         0.03739130  0.05923611           0.9256443
#rf3         0.03173913  0.05512047           0.9271396
#rf4         0.02847826  0.05195426           0.9269400
#rf5         0.02565217  0.04784719           0.9275078
#rf6         0.02543478  0.04580106           0.9293413
#rf7         0.02434783  0.04508941           0.9279504
#rf8         0.02565217  0.04484890           0.9267517
#rf9         0.02630435  0.04487768           0.9264383
#rf10        0.02543478  0.04500928           0.9252461
#rf11        0.02565217  0.04432214           0.9248013
#rf12        0.02260870  0.04319396           0.9247300
#rf13        0.02456522  0.04365180           0.9231657
#rf14        0.02413043  0.04442122           0.9221335
#rf15        0.02478261  0.04491575           0.9205935
#rf16        0.02500000  0.04463868           0.9189861
#rf17        0.02456522  0.04440723           0.9176113
#rf18        0.02326087  0.04619446           0.9137035
#rf19        0.02347826  0.04697938           0.9113126
#rf20        0.02456522  0.05016003           0.9061300
#rf21        0.02500000  0.05143319           0.9020687
#rf22        0.02521739  0.05357631           0.8968239

comparison <- compare(dalike,plot = TRUE,ylim=c(0,0.25), measure = c("brier score"), col=c("white"))#,"white","white","white","white","white","white","white","white","white","white","white","white","white","white"))

top.sel = toplist(sel,k=50,iter=1)

exp.core <- exp.combat.consensus[,rownames(core)]

exp.core[1:5,1:5]

#                     03_04_2013_A06_3191.CEL 03_04_2013_A07_3170.CEL 03_04_2013_B05_3273.CEL 03_04_2013_B11_2547.CEL 03_04_2013_C06_2765.CEL
#ENSG00000000938                9.835223                9.175543                9.793752                8.935259                9.416509
#ENSG00000001084                3.255816                3.677825                3.284701                3.412334                3.477205
#ENSG00000001167                5.103573                4.852766                4.860181                4.685487                4.645768
#ENSG00000001461                4.703481                4.252066                4.898815                4.843714                4.973605
#ENSG00000001497                4.199053                4.284692                4.323344                4.020702                4.583923

exp.norm[1:5,1:5]

#                     03_04_2013_A06_3191.CEL 03_04_2013_A07_3170.CEL 03_04_2013_B05_3273.CEL 03_04_2013_B11_2547.CEL 03_04_2013_C06_2765.CEL
#ENSG00000000938               0.7424130               0.6735182               0.8432778               0.6795802               0.6968092
#ENSG00000001084               0.2526683               0.2849291               0.2423196               0.2608933               0.2674523
#ENSG00000001167               0.3787524               0.3539973               0.3806146               0.3531788               0.3679799
#ENSG00000001461               0.3797446               0.3083979               0.3842116               0.3637744               0.3880234
#ENSG00000001497               0.3227176               0.3187273               0.3318100               0.3226539               0.3388419

### classifier tests

library(randomForest)

exp.class <- exp.core[rownames(class),]
c.core <- c.1[colnames(exp.core.class),]

dim(exp.core.class)
exp.core.class[1:5,1:5]

cts <- as.factor(core$CTS)

rf <- randomForest(cse~., data=t(exp.core.class), proximity=TRUE) 

# Predict posterior probabilities
pred_probs <- predict(rf, t(vanish.class), type = "prob")

# Display the posterior probabilities
head(pred_probs)
pred_probs <- as.data.frame(pred_probs)
pred_probs$chipID <- rownames(pred_probs)
pred_pr
write.table(pred_probs,file="posterior_probabilities_ALL.txt")

plot(pred_probs)
                              
print(rf)

#Call:
#  randomForest(formula = cse ~ ., data = t(exp.class), proximity = TRUE) 
#Type of random forest: classification
#Number of trees: 500
#No. of variables tried at each split: 4
#
#OOB estimate of  error rate: 2.17%
#Confusion matrix:
#  1  2   3 class.error
#1 214  0   1 0.004651163
#2   2 77   2 0.049382716
#3   1  4 159 0.03048780

exp.class <- exp.final[rownames(class),]

exp.class[1:5,1:5]


### predict CTS in co-normalized VANISH

p2 <- predict(rf, t(vanish.class))

summary(p2)

p2 <- as.data.frame(p2)
head(p2)

p2$chipID <- rownames(p2)
head(p2)

p1                  chipID
03_04_2013_A01_3213.CEL  1 03_04_2013_A01_3213.CEL
03_04_2013_A03_3199.CEL  1 03_04_2013_A03_3199.CEL
03_04_2013_A05_3193.CEL  3 03_04_2013_A05_3193.CEL
03_04_2013_A06_3191.CEL  1 03_04_2013_A06_3191.CEL
03_04_2013_A07_3170.CEL  2 03_04_2013_A07_3170.CEL
03_04_2013_A09_3172.CEL  2 03_04_2013_A09_3172.CEL

##### silhouette

library(cluster)
cts.vn <- p2$p2
rf <- randomForest(cts.vn~., data=t(vanish.class), proximity=TRUE) 

proximity_matrix <- rf$proximity
distance_rf <- as.dist(1 - proximity_matrix)

sil=silhouette(as.numeric(cts.vn),dist=distance_rf) # silhouette function


fviz_silhouette(sil)


# plot the results to pdf
pdf("silhouettes_VANISHsamples.pdf")
plot(sil,col=c("royalblue", "#B2DF8A", "orange"))
dev.off()

###

